{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c004acc-13cd-4917-8480-592c7c2d623b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Change that following variable settings match your deployed model's *Inference endpoint*. for example: \n",
    "\n",
    "```\n",
    "vllm_endpoint = \"https://model-vllm.apps.clusterx.sandboxx.opentlc.com\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de65d02-84a6-4cff-882e-551cdd42b486",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vllm_endpoint = \"https://granite-vllm-modelcar-serverless.apps.cluster-5ct9x.5ct9x.sandbox970.opentlc.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f9ece-e9cf-44e2-a8a2-73160186aee8",
   "metadata": {},
   "source": [
    "## Chat completion with Requests library\n",
    "\n",
    "Build and submit the REST request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9386f-683a-4880-b780-c40bec3ab9f8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_model(endpoint):\n",
    "    models_endpoint = f\"{endpoint}/v1/models\"\n",
    "    response = requests.get(models_endpoint)\n",
    "    model = response.json()[\"data\"][0][\"id\"]\n",
    "    return model\n",
    "\n",
    "def completion_request(prompt, model, endpoint):\n",
    "    completion_endpoint = f\"{endpoint}/v1/completions\"\n",
    "    json_data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": [\n",
    "            prompt\n",
    "        ],\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 1,\n",
    "        \"n\": 1,\n",
    "        \"stream\": False,\n",
    "        \"logprobs\": 0,\n",
    "        \"echo\": False,\n",
    "        \"stop\": [\n",
    "            \"string\"\n",
    "        ],\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"best_of\": 1,\n",
    "        \"user\": \"string\",\n",
    "        \"top_k\": -1,\n",
    "        \"ignore_eos\": False,\n",
    "        \"use_beam_search\": False,\n",
    "        \"stop_token_ids\": [\n",
    "            0\n",
    "        ],\n",
    "        \"skip_special_tokens\": True,\n",
    "        \"spaces_between_special_tokens\": True,\n",
    "        \"repetition_penalty\": 1,\n",
    "        \"min_p\": 0,\n",
    "        \"include_stop_str_in_output\": False,\n",
    "        \"length_penalty\": 1\n",
    "    }\n",
    "\n",
    "    # If using RHOAI 2.13 or new, set `verify=True`\n",
    "    # Older versions utilize a self-signed cert that is not trusted by default\n",
    "    response = requests.post(completion_endpoint, json=json_data, verify=True)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00de400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(vllm_endpoint)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad16ac-23da-48bd-9796-f8e4cacae981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = completion_request(\"What is AI?\", model, vllm_endpoint)\n",
    "print(prediction[\"choices\"][0][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
